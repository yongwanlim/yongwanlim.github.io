<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Yongwan Lim | Product review generation using conditional generative language model</title>
  <meta name="description" content="">

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/projects/1_project/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Yongwan</strong> Lim
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">about</a>

        <!-- Blog -->
        <!-- <a class="page-link" href="/blog/">blog</a>-->

        <!-- Pages -->
        
          
        
          
            <a class="page-link" href="/research/">research</a>
          
        
          
            <a class="page-link" href="/publications/">publications</a>
          
        
          
            <a class="page-link" href="/projects/">projects</a>
          
        
          
        
          
        
          
        

        <!-- CV link -->
        <a class="page-link" href="/assets/pdf/yongwan_cv.pdf">vitae</a> 

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Product review generation using conditional generative language model</h1>
    <h5 class="post-description">CSCI 566 2019 Fall Project (NLP TextGen)</h5>
  </header>

  <article class="post-content Product review generation using conditional generative language model clearfix">
    <p><strong><em>Taejin Park, Yongwan Lim, Yichen Zhou, Kaixi Wang</em></strong></p>

<h4 id="code-slides"><a href="https://bitbucket.org/taejinpa/cvae-textgen">[CODE]</a> <a href="https://docs.google.com/presentation/d/e/2PACX-1vS1R_IaLbmIQYgMBN3piap-J5ubM0HCLHQX7a70T9zbBMlo8D9Mnpmv2jIh27lxJv1gCgjxuadSFIG5/pub?start=false&amp;loop=false&amp;delayms=3000">[SLIDES]</a></h4>

<h3 id="motivation"><strong>Motivation</strong></h3>

<p>The rise of deep neural-network based approaches has significantly improved natural dialog with machines in the past few years. While conditional generative models have been successfully deployed in image/video applications, there is still much that can be done with generative language models such as VAE [1] and GPT2 [2-3] in text and language applications.</p>

<h3 id="goal-of-this-project"><strong>Goal of this project</strong></h3>

<p>The goal of this project is to artificially generate semantically and syntactically correct product review comments given human inputted keyword prompts. Specifically, we are trying to address the question: <em>Can we generate text while controlling the output?</em> If we can control the output of generated text, we can apply this technique to many real life applications, including chat-bot, AI speaker, predictive text, and many others.</p>

<div class="img_row">
<img class="col three left" src="/assets/img/project1_fig1.png" alt="" title="fig1" />
</div>

<p>We expect this project to have the following features:</p>
<ul>
  <li>Generative language model</li>
  <li>Keyword prompts input: sentiment (rating), subject (product name), aggressiveness (vocabulary)</li>
  <li>Grammatically correct sentence output that contains a distinct context</li>
</ul>

<h3 id="problem-definition"><strong>Problem Definition</strong></h3>

<p>To artificially generate semantically and syntactically correct review sentences given human inputted keyword prompts.</p>
<ul>
  <li>Training input: review texts, rating 1 or 5</li>
  <li>Inference
    <ul>
      <li>Input: review rating 1 or 5</li>
      <li>Output: review sentences containing and/or reflecting the given distinct context and sentiment</li>
    </ul>
  </li>
</ul>

<p>This would require us to being able to have randomness and controllability at the same time.
The main challenges of this problem would be that:</p>

<ul>
  <li>The generated output is often independent of the conditioning input (mode collapse).</li>
  <li>Quality of generated sentence (repetitive phrases, too general output)</li>
</ul>

<h3 id="traditional-method"><strong>Traditional Method</strong></h3>

<h4 id="conditional-variational-auto-encoder-cvae-1">Conditional Variational Auto-Encoder (CVAE) [1]</h4>

<h4 id="training">Training</h4>

<div class="img_row">
<img class="col three left" src="/assets/img/project1_fig2.png" alt="" title="fig2" />
</div>
<div class="col three caption">
Training mode CVAE
</div>

<ul>
  <li>Conditional VAE system that uses keyword/sentiment as conditional input.</li>
  <li>Both encoder and decoder take the keyword input during training.</li>
</ul>

<h4 id="inference">Inference</h4>

<div class="img_row">
<img class="col three left" src="/assets/img/project1_fig3.png" alt="" title="fig3" />
</div>
<div class="col three caption">
Inference mode CVAE
</div>

<ul>
  <li>Decoder outputs a few sentences of review about a product driven by keyword input.</li>
  <li>Random noise input can work as a seed for generated review.</li>
  <li><strong>Limitation of conventional CVAE</strong> : the decoder ignores conditional input (mode collapse)
    <ul>
      <li>Example:
        <ul>
          <li>1-star input, 100 noise samples ➝  44 positive, 56 negative output</li>
          <li>5-star input, 100 noise samples ➝  61 positive, 39 negative output</li>
        </ul>
      </li>
      <li>Even if we provide conditioning input to decoder, the sentiment is heavily dependent on random signal and conditioning input is not able to change the sentiment already ingrained in the random noise.</li>
      <li>Thus, we need more powerful and efficient way to enforce the sentiment to the training and inference systems.</li>
    </ul>
  </li>
</ul>

<h3 id="proposed-method-improved-cvae"><strong>Proposed Method: Improved CVAE</strong></h3>
<h4 id="training-cvae--discriminator">Training (CVAE + <strong>Discriminator</strong>)</h4>

<div class="img_row">
<img class="col three left" src="/assets/img/project1_fig4.png" alt="" title="fig4" />
</div>
<div class="col three caption">
Training: CVAE + "Discriminator"
</div>

<ul>
  <li>Discriminator is a classifier that predicts sentiment of a word sequence generated by the decoder.</li>
  <li>Attaching discriminator enables the model to backpropagate the error from the sentiment (star rating) labels thus leads to more accurate sentiment.</li>
</ul>

<h4 id="inference-conditional-decoder--discriminator--filtering">Inference (<strong>Conditional</strong> Decoder + <strong>Discriminator</strong> + <strong>Filtering</strong>)</h4>

<div class="img_row">
<img class="col three left" src="/assets/img/project1_fig5.png" alt="" title="fig5" />
</div>
<div class="col three caption">
"Conditional" Decoder + "Discriminator"
</div>

<ul>
  <li>Since conventional CVAE system ignores the conditioning input, we can force the conditioned word output by leveraging the discriminator.</li>
  <li>The alpha value balances between the softmax value from discriminator and the softmax value from the decoder.</li>
  <li>If the alpha value is close to 0, the model outputs very plausible and grammatically correct sentence but with inaccurate sentiment.</li>
  <li>If the alpha value is close to 1, the model generates a sentence that expresses more accurate sentiment but is often grammatically and semantically incorrect.</li>
</ul>

<div class="img_row">
<img class="col three left" src="/assets/img/project1_fig6.png" alt="" title="fig6" />
</div>
<div class="col three caption">
"Conditional" Decoder + "Discriminator" + "Filtering"
</div>

<ul>
  <li>If text output is not giving a certain amount of confidence in terms of softmax value of the discriminator, we drop the output text and regenerate it.</li>
</ul>

<h3 id="neural-network-training"><strong>Neural Network Training</strong></h3>

<ul>
  <li>Training Dataset:  Amazon review dataset [4]
    <ul>
      <li>Trained on a subset of 5 major categories (Electronics, mobile electronics, major appliances, and etc)</li>
      <li>Trained on total 0.6M reviews</li>
      <li>Vocabulary size of 60K words</li>
      <li>Limit sentence length between 20 and 60 words, including punctuations.</li>
      <li>Only use 1-star (negative) and 5-star (positive) ratings</li>
      <li>66% negative / 33% positive data (*Since negative comments tend to have more variability, doubling the dataset of negative training data balances the variability of output text’s sentiment)</li>
      <li>
        <p>Example of training dataset:</p>

        <p><code class="language-plaintext highlighter-rouge">Reviewer ID: R1KKOXHNI8MSXU</code><br />
  <code class="language-plaintext highlighter-rouge">Product category: Apparel</code> <br />
  <code class="language-plaintext highlighter-rouge">Review text: “This is the second leggings I have ordered, I wear both of them often. They wash well and I receive many compliments on them!”</code> <br />
  <code class="language-plaintext highlighter-rouge">5-star rating of the product: 5</code> <br />
  <code class="language-plaintext highlighter-rouge">Helpful votes: 3</code></p>
      </li>
    </ul>
  </li>
  <li>Environment
    <ul>
      <li>Pytorch 0.4.1, CUDA 10.0, Python 3.6</li>
    </ul>
  </li>
</ul>

<h3 id="experiments"><strong>Experiments</strong></h3>
<p>We test the effectiveness of the proposed methods in terms of sentiment accuracy measure:</p>

<ol>
  <li>Conditional decoder
    <ul>
      <li>The conditional output accuracy is dependent on 𝜶.</li>
      <li>Check how output text varies over different 𝜶.</li>
    </ul>
  </li>
  <li>Output filtering
    <ul>
      <li>Rejects the output text with low discriminator output softmax probability</li>
    </ul>
  </li>
</ol>

<p>Sentiment accuracy is used as a performance metric, which is measured by BERT (Transformer) + LSTM sentiment classifier trained on IMDB dataset. For sanity check, we ensure that the classifier reaches accuracy of 92.31% for IMDB test set.</p>

<h3 id="evaluation"><strong>Evaluation</strong></h3>
<p>We evaluate the quality of artificially generated sentences along the following two dimensions:</p>
<ol>
  <li>Evaluation by humans:
    <ul>
      <li>
        <p>15 participants</p>
      </li>
      <li><strong>Task 1</strong>: Real vs Generated
        <ul>
          <li>48 comments; 24 real, 24 generated</li>
          <li>Machine generated texts are shuffled with human generated text.</li>
          <li>Evaluators were asked whether they think the review is generated by human or machine.</li>
        </ul>
      </li>
      <li><strong>Task 2</strong>: Sentiment Classification
        <ul>
          <li>48 comments; 24 1-star, 24 5-star</li>
          <li>Evaluators were asked whether they think the review is positive or negative.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Evaluation by algorithm:
    <ul>
      <li>BERT model-based Bi-LSTM sentiment classifier (the same system as in <em>Experiments</em> section)</li>
      <li>
        <p>Trained on IMDB data using BERT embeddings (IMDB test set accuracy: 92.31%)</p>
      </li>
      <li><strong>Task 2</strong>: Sentiment Classification
        <ul>
          <li>48 comments; 24 1-star, 24 5-star</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h3 id="results"><strong>Results</strong></h3>
<h4 id="control-between-sentiment-and-syntax">Control between sentiment and syntax</h4>
<ul>
  <li>Example of conditional decoder output of negative condition, star rating 1.</li>
</ul>
<div class="img_row">
<img class="col three left" src="/assets/img/project1_fig8.png" alt="" title="fig8" />
</div>
<div class="col three caption">
Conditional decoder output with a range of 𝜶
</div>

<ul>
  <li>If alpha is 0, there is no influence of discriminator, and it sometimes generates sentiment that does not correspond to the given sentiment (For a given star rating of 1 but alpha of 0, the sentence says “she loves it”)</li>
  <li>Higher alpha values show grammatical errors (e.g. These are a terrible product) or sentences do not make any sense (e.g. no distortion when it goes)</li>
</ul>

<h4 id="improvement-of-sentiment-accuracy-by-conditional-decoder-and-output-filtering">Improvement of sentiment accuracy by conditional decoder and output filtering</h4>
<div class="img_row">
<img class="col three left" src="/assets/img/project1_fig9.png" alt="" title="fig9" />
</div>

<ul>
  <li>Sentiment accuracy is evaluated with different 𝜶 and 𝜶=0.65 gives the best performance while showing a good balance between grammar and accurate sentiment.</li>
  <li>All the following evaluation is done with alpha value of 0.65.</li>
</ul>

<h4 id="task-1-real-vs-generated">Task 1: Real vs Generated</h4>
<ol>
  <li>Evaluation by Humans: <strong>Accuracy (F1 score): 70.83% (73.31%)</strong>
    <div class="img_row">
 <img class="col three left" src="/assets/img/project1_fig10.png" alt="" title="fig10" />
 </div>
    <ul>
      <li>50% is chance probablity and this means that some texts are very plausible while some are not.</li>
      <li><em>Highlights</em> of evaluation by humans</li>
    </ul>
    <div class="img_row">
 <img class="col three left" src="/assets/img/project1_fig11.png" alt="" title="fig11" />
 </div>
    <ul>
      <li>We picked three sentences that all the human annotators said “Real” comments. These sentences show very consistent sentiment.</li>
      <li>We also picked three sentences that all the human annotators said “Generated”, which means failed output. These sentences show lots of conflicting sentiment and semantically incorrect phrases.</li>
    </ul>
  </li>
</ol>

<h4 id="task-2-sentiment-accuracy">Task 2: Sentiment Accuracy</h4>
<ol>
  <li>Evaluation by humans: <strong>Accuracy (F1 score):  87.5% (88.00%)</strong>
    <ul>
      <li>Ground truth: majority vote of annotated sentiment scores (0 generated or 1 real)</li>
      <li><em>Highlights</em> of evaluation by humans</li>
    </ul>
    <div class="img_row">
 <img class="col three left" src="/assets/img/project1_fig12.png" alt="" title="fig12" />
 </div>
    <ul>
      <li>We picked the sentences with coherent sentiment outcome from human annotators. These sentences have very consistent sentiment in each sentence.</li>
      <li>We also picked the sentences which have conflicting annotations. These sentences have inconsistent sentiment which means failed output.</li>
    </ul>
  </li>
  <li>Evaluation by machine: <strong>Accuracy (F1 score): 77.08% (80.70%)</strong>
    <ul>
      <li>This score is from the softmax value of positive/negative sentiment class in BERT + BiLSTM model trained on IMDB dataset.</li>
      <li>BERT + BiLSTM model tends to misclassify negative sentence as positive sentence since there are plenty of negative expressions that do not exist in IMDB dataset. (e.g. This plastic cover do not fit into my camera and very cheaply made.)</li>
    </ul>
  </li>
  <li>Sentiment Score Comparison Machine vs Humans
    <div class="img_row">
 <img class="col three left" src="/assets/img/project1_fig7.png" alt="" title="fig7" />
 </div>
    <ul>
      <li>This correlation reflects the credibility of algorithm (machine)-based evaluation.</li>
      <li>There are few highly conflicting outcomes: Human annotators are far better at capturing semantics from the text to judge the actual sentiment.</li>
    </ul>
  </li>
</ol>

<h3 id="additional-work-pretrained-model-gpt-2-based-text-generation"><strong>Additional Work: Pretrained model (GPT-2) based text generation</strong></h3>

<h4 id="click-product-review-generation-using-gpt2-model"><a href="https://github.com/tango4j/usc_cs566_project/blob/master/gpt2_work.md">(CLICK) Product review generation using GPT2 model</a></h4>
<ul>
  <li>Click the above link to view the details.</li>
  <li>Besides our proposed improved CVAE model, we also approahced this problem with pretrained language model (GPT-2).</li>
  <li>For pretrained language model, we fined tuned the model with refined training dataset by filtering “helpfulness” in amazon review dataset.</li>
  <li>Here are some examples from fine-tuned GPT-2 based text generation system:</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Score</th>
      <th>Headline</th>
      <th>Review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>5</td>
      <td>I would buy those again</td>
      <td>I absolutely love these, even though the price was such that I did not get them in time. The sound is amazing and I would recommend these.</td>
    </tr>
    <tr>
      <td>2</td>
      <td>This item never came</td>
      <td>If you are looking at something for cheap, it would be very nice to receive an item that never came.  This item did not come after 2 weeks.  I emailed Amazon who did not even respond to my email.</td>
    </tr>
    <tr>
      <td>5</td>
      <td>Just what I was looking for</td>
      <td>My husband is always wanting to get a Bluetooth headset and has now found the ideal one in my pocket. It holds his music perfectly and is comfortable. It also has great sound quality for listening to music. Great sound, great built-in mic, and the Bluetooth connection works wonderfully. My husband can use his laptop to play his MP3 player while he works. The speakers work just fine on it. It is a bit loud but I get it loud. The headphones are very long and this is a great fit for those who want an outside ear, as well as others who require some sort of earbud. All in all, a great product for such a reasonable price.</td>
    </tr>
  </tbody>
</table>

<h3 id="conclusion"><strong>Conclusion</strong></h3>
<ol>
  <li>The challenge of ignored condition
    <ul>
      <li>Input condition to CVAE can be ignored and lead to mode collapse.</li>
      <li>Conditional generative model should be carefully designed to avoid ignored condition problem.</li>
    </ul>
  </li>
  <li>Conditional decoder and output filtering
    <ul>
      <li>Conditional decoder leverages the discriminator’s ability to force the condition input.</li>
      <li>Output filtering also improves the quality of generated text.</li>
    </ul>
  </li>
</ol>

<h3 id="future-work"><strong>Future Work</strong></h3>
<ol>
  <li>Consistency of sentiment:
    <ul>
      <li>Time varying conditional decoder’s 𝜶 value that controls the condition</li>
      <li>Self attention algorithm to focus on the certain part of the generated text.</li>
    </ul>
  </li>
  <li>Generative method coupled with CVAE+Discriminator
    <ul>
      <li>A way to modify the random input to prevent the condition ignoring problem</li>
    </ul>
  </li>
</ol>

<h3 id="reference"><strong>Reference</strong></h3>
<p>[1] K. Sohn, H. Lee, and X. Yan. Learning Structured Output Representation using Deep Conditional Generative Models. <em>Advances in Neural Information Processing Systems</em>. 2015.   <br />
[2] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei and I. Sutskever. <em>Language Models are Unsupervised Multitask Learners</em>. 2019.<br />
[3] GPT-2 Model release: https://www.openai.com/blog/better-language-models/<br />
[4] Amazon review dataset: http://jmcauley.ucsd.edu/data/amazon/</p>

<hr />
<p><em>Written by Yongwan Lim and Taejin Park on Dec. 5. 2019</em></p>

<hr />

  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2021 Yongwan Lim.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-166081774-1', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
